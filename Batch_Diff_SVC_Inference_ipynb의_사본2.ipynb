{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suminpark123/Side/blob/main/Batch_Diff_SVC_Inference_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B82.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP5rRkbTpnG8"
      },
      "source": [
        "# **[Diff-SVC](https://github.com/prophesier/diff-svc)**\n",
        "Singing Voice Conversion via diffusion model\n",
        "\n",
        "____\n",
        "\n",
        "####  **Notebook put together by [justinjohn-03](https://github.com/justinjohn0306)**\n",
        "#### **Edited for batch rendering by [MLo7](https://github.com/MLo7Ghinsan)**\n",
        "\n",
        "## **Special thanks to [prophesier](https://github.com/prophesier) and [UtaUtaUtau](https://github.com/UtaUtaUtau)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nnusihSv2a9",
        "outputId": "9b9f4b81-17a7-4bc3-92dc-d0fa4b54dd54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## Mount your Gdrive \n",
        "#@markdown (This is an essential step if you want to load your own trained model)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Mux_wwBggJKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937f2c0b-3ced-4b11-98ec-ccb3e7a1213a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#@title # Setup\n",
        "#@markdown ## Install Diff-SVC\n",
        "from IPython.display import clear_output \n",
        "from google.colab import files \n",
        "import os\n",
        "\n",
        "!rm -rf /content/sample_data\n",
        "\n",
        "\n",
        "Mode = \"install\" #@param [\"install\", \"update\", \"remove\"]\n",
        "Repository = \"UtaUtaUtau\" #@param [\"Official Diff-SVC\", \"UtaUtaUtau\"]\n",
        "Branch_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "repositories = {\n",
        "  'Official Diff-SVC':'prophesier',\n",
        "  'UtaUtaUtau':'UtaUtaUtau'\n",
        "}\n",
        "\n",
        "from pathlib import Path\n",
        "if Mode == 'install':\n",
        "  git_cmd = ''\n",
        "  if Branch_name: git_cmd += f\"-b {Branch_name} \"\n",
        "\n",
        "  git_cmd += f\"--depth 1 https://github.com/{repositories[Repository]}/diff-svc.git\"\n",
        "  !git clone $git_cmd\n",
        "  %cd /content/diff-svc\n",
        "  print('Installing torch')\n",
        "  !pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "  !pip install -r requirements_short.txt\n",
        "  !pip install tensorboard<2.9,>=2.8\n",
        "  %reload_ext tensorboard\n",
        "  print('Downloading pretrained models')\n",
        "  %cd \"/content/\"\n",
        "  %mkdir -p /content/diff-svc/checkpoints/\n",
        "  !wget https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/diff-svc-necessary-checkpoints/0102_xiaoma_pe.zip\n",
        "  !wget https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/diff-svc-necessary-checkpoints/0109_hifigan_bigpopcs_hop128.zip\n",
        "  !wget https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/diff-svc-necessary-checkpoints/nsf_hifigan.zip\n",
        "  !wget https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/diff-svc-necessary-checkpoints/hubert.zip\n",
        "  !mkdir /content/diff-svc/checkpoints/0102_xiaoma_pe\n",
        "  !mkdir /content/diff-svc/checkpoints/0109_hifigan_bigpopcs_hop128\n",
        "  !mkdir /content/diff-svc/checkpoints/nsf_hifigan\n",
        "  !mkdir /content/diff-svc/checkpoints/hubert\n",
        "  !unzip /content/0102_xiaoma_pe.zip -d /content/diff-svc/checkpoints/0102_xiaoma_pe\n",
        "  !unzip /content/0109_hifigan_bigpopcs_hop128.zip -d /content/diff-svc/checkpoints/0109_hifigan_bigpopcs_hop128\n",
        "  !unzip /content/nsf_hifigan.zip -d /content/diff-svc/checkpoints/nsf_hifigan\n",
        "  !unzip /content/hubert.zip -d /content/diff-svc/checkpoints/hubert\n",
        "\n",
        "  !rm /content/0102_xiaoma_pe.zip\n",
        "  !rm /content/0109_hifigan_bigpopcs_hop128.zip\n",
        "  !rm /content/nsf_hifigan.zip\n",
        "  !rm /content/hubert.zip\n",
        "\n",
        "  !rm /content/diff-svc/results/test_output.wav\n",
        "\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  print('Done!')\n",
        "\n",
        "elif Mode == 'update':\n",
        "  %cd /content/diff-svc\n",
        "  !git pull\n",
        "  !pip install -r requirements_short.txt\n",
        "  clear_output()\n",
        "  print(\"Done!\")\n",
        "else:\n",
        "  answer = input(\"Are you sure you want to delete diff-svc folder? (y/n)\").lower()\n",
        "  while answer not in [\"y\", \"n\"]:\n",
        "    print(\"Invalid input\")\n",
        "    answer = input(\"Are you sure you want to delete diff-svc folder? (y/n)\").lower()\n",
        "  if answer == \"y\":\n",
        "    %cd /content\n",
        "    %rm -r diff-svc/\n",
        "    print(\"Done!\")\n",
        "  else:\n",
        "    print(\"Cancelled...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7rtUN0uPu9h"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/zshicode/GNN-for-text-classification.git\n",
        "%cd GNN-for-text-classification/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awzgZDSuPyZK"
      },
      "outputs": [],
      "source": [
        "! pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZHaH4K7RCFV"
      },
      "outputs": [],
      "source": [
        "! pip install hparams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlM9RgYviRhy",
        "outputId": "481c725d-7e85-405d-ca43-df8054b47f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diff-svc\n",
            "| load 'model' from '/content/drive/MyDrive/SVC/SugarData/SAVE/model_ckpt_steps_120000.ckpt'.\n",
            "| load 'model' from 'checkpoints/0102_xiaoma_pe/model_ckpt_steps_60000.ckpt'.\n",
            "| Load HifiGAN:  checkpoints/nsf_hifigan/model\n",
            "Removing weight norm...\n",
            "model loaded\n"
          ]
        }
      ],
      "source": [
        "#@title # **Load model**\n",
        "\n",
        "#@markdown ### **Load the pretrained model (default)**\n",
        "\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown Note: Add the full path to the most recent checkpoint located on your Gdrive as well as the speaker's name if you wish to use your own model.\n",
        "\n",
        "#@markdown Example:-\n",
        "\n",
        "#@markdown The ``project_name`` will be the name of your speaker\n",
        "\n",
        "#@markdown  ``model_path: /content/drive/MyDrive/Diff-SVC/checkpoints/model_name/model_ckpt_steps_50000.ckpt``\n",
        "\n",
        "#@markdown           ``config_path: /content/drive/MyDrive/Diff-SVC/checkpoints/model_name/config.yaml``\n",
        "\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown ### **Set model location with the name of the speaker:**\n",
        "#@markdown *If you wish to use the pre-trained model and don't have your own model, leave these at their default values.*\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "%cd \"/content/diff-svc/\"\n",
        "\n",
        "os.environ['PYTHONPATH']='.'\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "\n",
        "from utils.hparams import hparams\n",
        "from preprocessing.data_gen_utils import get_pitch_parselmouth,get_pitch_crepe\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import utils\n",
        "import librosa\n",
        "import torchcrepe\n",
        "from infer import *\n",
        "import logging\n",
        "from infer_tools.infer_tool import *\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "\n",
        "# 工程文件夹名，训练时用的那个\n",
        "project_name = \"s\" #@param {type: \"string\"}\n",
        "model_path = \"/content/drive/MyDrive/SVC/SugarData/SAVE/model_ckpt_steps_120000.ckpt\" #@param {type: \"string\"}\n",
        "config_path=\"/content/drive/MyDrive/SVC/SugarData/SAVE/config.yaml\" #@param {type: \"string\"}\n",
        "hubert_gpu=True\n",
        "svc_model = Svc(project_name,config_path,hubert_gpu, model_path)\n",
        "print('model loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "mbmB1R2as9m2",
        "outputId": "7fb7182e-99ea-4f52-a891-58906d2acf5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/diff-svc/raw\n",
            "\n",
            "\u001b[34m\u001b[1mupload your reference audio\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11c0f298-fb6d-46fb-9da3-57f0bba370ed\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-11c0f298-fb6d-46fb-9da3-57f0bba370ed\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-665f07a5bf43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\033[34m\\033[1mupload your reference audio\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlistfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\"/content/diff-svc/\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   \"\"\"\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    145\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    146\u001b[0m           input_id=input_id, output_id=output_id))\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@markdown ## Upload your reference audio\n",
        "\n",
        "%cd \"/content/diff-svc/raw/\"\n",
        "\n",
        "print(\"\\n\\033[34m\\033[1mupload your reference audio\")\n",
        "listfn, length = files.upload().popitem()\n",
        "\n",
        "%cd \"/content/diff-svc/\"\n",
        "print(\"\\n\\033[32m\\033[1mdone\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n34McW_Q0-iF"
      },
      "outputs": [],
      "source": [
        "#@markdown # Import your audio\n",
        "\n",
        "%cd \"/content/diff-svc\"\n",
        "\n",
        "#@markdown File location in Drive\n",
        "\n",
        "#@markdown Or you can simply drag and drop your files into batch_audio folder after running this cell (remove the directory in this cell first)\n",
        "audio_location = '' #@param {type: \"string\"}\n",
        "!mkdir -p batch_audio\n",
        "audio_clone = \"batch_audio\"\n",
        "!rm /raw/test_input.wav\n",
        "if audio_location.endswith('.rar'):\n",
        "    !unrar x \"$audio_location\" \"$audio_clone\"\n",
        "elif audio_location.endswith('.zip'):\n",
        "    !unzip \"$audio_location\" -d \"$audio_clone\"\n",
        "elif audio_location.endswith('.tar'):\n",
        "    !tar -xf \"$audio_location\" -C \"$audio_clone\"\n",
        "elif audio_location.endswith('.tar.gz'):\n",
        "    !tar -xzf \"$audio_location\" -C \"$audio_clone\"\n",
        "elif audio_location.endswith('.tar.bz2'):\n",
        "    !tar -xjf \"$audio_location\" -C \"$audio_clone\"\n",
        "else:\n",
        "    !7za x \"$audio_location\" -o$audio_clone\n",
        "  \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DauP3lXimfS3",
        "outputId": "05f2166e-2564-46e9-8280-1ce337909d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diff-svc/batch_audio/레드솔치후유2_레드솔.wav\n",
            "code version:2022-12-04\n",
            "load chunks from temp\n",
            "#=====segment start, 0.295s======\n",
            "jump empty segment\n",
            "#=====segment start, 11.904s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.017s\n",
            "hubert (on cuda) time used 0.4849429130554199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:02<00:00, 46.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 2.150s\n",
            "executing 'after_infer' costed 0.577s\n",
            "#=====segment start, 21.451s======\n",
            "jump empty segment\n",
            "#=====segment start, 32.848s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.043s\n",
            "hubert (on cuda) time used 2.5274734497070312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:05<00:00, 18.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 5.377s\n",
            "executing 'after_infer' costed 1.576s\n",
            "#=====segment start, 0.139s======\n",
            "jump empty segment\n",
            "#=====segment start, 20.108s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.019s\n",
            "hubert (on cuda) time used 0.7984442710876465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:03<00:00, 27.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 3.598s\n",
            "executing 'after_infer' costed 0.975s\n",
            "#=====segment start, 6.598s======\n",
            "jump empty segment\n",
            "#=====segment start, 33.139s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.034s\n",
            "hubert (on cuda) time used 2.6018424034118652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:05<00:00, 18.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 5.497s\n",
            "executing 'after_infer' costed 1.605s\n",
            "#=====segment start, 0.074s======\n",
            "jump empty segment\n",
            "#=====segment start, 20.19s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.025s\n",
            "hubert (on cuda) time used 0.8105733394622803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:03<00:00, 28.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 3.556s\n",
            "executing 'after_infer' costed 0.992s\n",
            "#=====segment start, 24.039s======\n",
            "jump empty segment\n",
            "#=====segment start, 14.036s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.041s\n",
            "hubert (on cuda) time used 1.1005220413208008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:02<00:00, 41.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 2.407s\n",
            "executing 'after_infer' costed 0.688s\n",
            "#=====segment start, 0.034s======\n",
            "jump empty segment\n",
            "#=====segment start, 6.054s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.025s\n",
            "hubert (on cuda) time used 0.4737677574157715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:01<00:00, 55.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 1.812s\n",
            "executing 'after_infer' costed 0.287s\n",
            "#=====segment start, 0.087s======\n",
            "jump empty segment\n",
            "#=====segment start, 10.57s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.018s\n",
            "hubert (on cuda) time used 0.412151575088501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:01<00:00, 50.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 1.995s\n",
            "executing 'after_infer' costed 0.519s\n",
            "#=====segment start, 0.031s======\n",
            "jump empty segment\n",
            "#=====segment start, 10.947s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.021s\n",
            "hubert (on cuda) time used 0.41533803939819336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:02<00:00, 49.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 2.014s\n",
            "executing 'after_infer' costed 0.539s\n",
            "#=====segment start, 0.438s======\n",
            "jump empty segment\n",
            "#=====segment start, 22.5s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.021s\n",
            "hubert (on cuda) time used 0.8394322395324707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:03<00:00, 25.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 3.860s\n",
            "executing 'after_infer' costed 1.093s\n",
            "#=====segment start, 0.259s======\n",
            "jump empty segment\n",
            "#=====segment start, 3.519s======\n",
            "load temp harvest f0\n",
            "executing 'get_pitch' costed 0.024s\n",
            "hubert (on cuda) time used 0.2841658592224121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sample time step: 100%|██████████| 100/100 [00:02<00:00, 44.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing 'diff_infer' costed 2.245s\n",
            "executing 'after_infer' costed 0.161s\n"
          ]
        }
      ],
      "source": [
        "#@title # Input audio and adjust parameters\n",
        "\n",
        "#@markdown ### <b><font color=\"red\"> Make sure that your imported audio have no subfolders before running this cell\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown #### ``This shifts the raw audio up by one semitone before rendering, if the raw input is of a male voice and the desired voice is female, you can input 8 or 12 etc (12 would shift a whole octave).``\n",
        "key = 0#@param {type: \"integer\"}\n",
        "# 加速倍数\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown #### ``The multiple of the inference acceleration , the default value is 1000 steps, inputting a value if 10 would mean only using 100 steps to render, it's a rather straightforward value. The value can go up to 50x (rendering in 20 steps) without causing audible quality loss, if the value is set any higher it may start to cause quality loss.``\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "\n",
        "#@markdown #### Note: ``If use_gt_mel is set to True below, you should keep this value lower than the add_noise_step value and keep it at a value where it can completely divide 1000.``\n",
        "\n",
        "\n",
        "pndm_speedup = 10 #@param {type: \"integer\"}\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown #### ``Related to the use_gt_mel parameter, it controls the balance of the input and target voice, a value of 1 is completely the raw input, a value of 1000 is completely the target voice, there's an audible mix in tone when the value falls around 300 (this value isn't linear, also, if this parameter is set very low, you can decrease the pndm exceleration value for higher rendering quality)``\n",
        "add_noise_step = 1000 #@param {type: \"integer\"}\n",
        "#@markdown ___\n",
        "#@markdown #### ``Crepe's noise filter threshold, you can increase the value of the raw audio is clean, and if there is a lot of noise, you can keep or decrease the value, changing the use_crepe parameter to False will disable this parameter.``\n",
        "thre = 1 #@param {type: \"integer\"}\n",
        "#@markdown ___\n",
        "#@markdown #### ``Crepe is a F0 calculation algorithm, it's good but slow, setting the value to False will change the F0 calculation algorithm from crepe to parselmouth that is faster than crepe but is of lower quality``\n",
        "use_crepe= False #@param {type:\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown #### ``F0 extraction algorithm for MEL spectogram rendering, using False will use the raw input's F0 for rendering. There's usually a difference in output between using True and False for rendering, usually setting it to True yields better results, but it's not set in stone, either value doesn't impact rendering speeds much. (Whatever the key value is, this is always changeable, doesn't affect it)``\n",
        "use_pe=True #@param {type:\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown #### ``This option is similar to the image-to-image function of AI art generation, if set to True, the output audio shall be a mix of the input voice and the target voice, the percentage of each is decided by the next parameter.``\n",
        "\n",
        "#@markdown #### ``NOTE!!!: If this parameter is set to true, keep the key parameter value at 0, as rendering with various pitch input is not supported.``\n",
        "use_gt_mel= False #@param {type:\"boolean\"}\n",
        "#@markdown ___\n",
        "#@markdown #### ``The folder of your audio files, default is batch_audio``\n",
        "folder = \"/content/diff-svc/batch_audio\" #@param {type: \"string\"}\n",
        "#@markdown ___\n",
        "for name in os.listdir(folder): \n",
        "    if name.endswith(\".wav\"):\n",
        "        wav_fn = os.path.join(folder, name)\n",
        "        print(wav_fn)\n",
        "        out_folder = \"results\"\n",
        "        wav_gen = os.path.join(out_folder, name)\n",
        "        f0_tst, f0_pred, audio = run_clip(svc_model,file_path=wav_fn, key=key, acc=pndm_speedup, use_crepe=use_crepe, use_pe=use_pe, thre=thre,\n",
        "                                        use_gt_mel=use_gt_mel, add_noise_step=add_noise_step,project_name=project_name,out_path=wav_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoungfUq8vA5",
        "outputId": "0a00206f-b7c9-47e3-cb3c-1bb6add3aea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Diff-SVC-RESULTS’: File exists\n",
            "  adding: results/ (stored 0%)\n",
            "  adding: results/레드솔치후유2_레드솔.wav (deflated 33%)\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Zip up the result to your drive\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "zip_exp_name = \"\\uC288\\uAC00 \\uB808\\uB4DC\\uC1945\" #@param {type:\"string\"}\n",
        "\n",
        "!mkdir /content/drive/MyDrive/Diff-SVC-RESULTS\n",
        "!zip -r \"/content/drive/MyDrive/Diff-SVC-RESULTS/{zip_exp_name}.zip\" \"results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8KCEfSI52R_m"
      },
      "outputs": [],
      "source": [
        "#@markdown # Delete old inputted wav and rendered wav\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown Run this cell if you want to redo the process, this cell will flush every .wav in results folder and batch_audio folder\n",
        "!rm -rf /content/diff-svc/batch_audio/*.wav\n",
        "!rm -rf /content/diff-svc/results/*.wav"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}